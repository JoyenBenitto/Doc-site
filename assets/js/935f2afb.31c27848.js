"use strict";(self.webpackChunkdoc_site=self.webpackChunkdoc_site||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"CUDA101","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"CUDA-101","href":"/docs/CUDA101/cuda101","docId":"CUDA101/cuda101","unlisted":false},{"type":"link","label":"CUDA-Programming","href":"/docs/CUDA101/cuda-programming","docId":"CUDA101/cuda_prog","unlisted":false},{"type":"link","label":"Organization of thread in a CUDA program Part-1","href":"/docs/CUDA101/Organization-of-thread-in-a-CUDA-program-Part-1","docId":"CUDA101/Organization_of_threads_p1","unlisted":false},{"type":"link","label":"Organization of thread in a CUDA program Part-2","href":"/docs/CUDA101/Organization-of-thread-in-a-CUDA-program-Part-2","docId":"CUDA101/Organization_of_threads_p2","unlisted":false},{"type":"link","label":"Unique index calculation part-1","href":"/docs/CUDA101/Unique_index-Part-1","docId":"CUDA101/Unique_index_Calculation_p1","unlisted":false},{"type":"link","label":"Unique index calculation part-2","href":"/docs/CUDA101/Unique_index-Part-2","docId":"CUDA101/Unique_index_Calculation_p2","unlisted":false},{"type":"link","label":"Memory transfer between host and device","href":"/docs/CUDA101/Memory-transfer-between-host-and-device","docId":"CUDA101/Memory transfer between host and device","unlisted":false},{"type":"link","label":"Device Properties","href":"/docs/CUDA101/Device-Properties","docId":"CUDA101/Device Properties","unlisted":false}],"href":"/docs/category/cuda101"}]},"docs":{"CUDA101/cuda_prog":{"id":"CUDA101/cuda_prog","title":"CUDA-Programming","description":"Understanding the basic elements of CUDA program:","sidebar":"tutorialSidebar"},"CUDA101/cuda101":{"id":"CUDA101/cuda101","title":"CUDA-101","description":"CUDA Programming Model","sidebar":"tutorialSidebar"},"CUDA101/Device Properties":{"id":"CUDA101/Device Properties","title":"Device Properties","description":"- Nvidia released their first CUDA toolkit in 2007.","sidebar":"tutorialSidebar"},"CUDA101/Memory transfer between host and device":{"id":"CUDA101/Memory transfer between host and device","title":"Memory transfer between host and device","description":"- In CUDA we work with two devices on the host and the device, so we have host memory and the device memory.","sidebar":"tutorialSidebar"},"CUDA101/Organization_of_threads_p1":{"id":"CUDA101/Organization_of_threads_p1","title":"Organization of thread in a CUDA program Part-1","description":"- CUDA runtime uniquely initialised #threadIdx variable for each thread depending on where that particular thread is located in the thread block.","sidebar":"tutorialSidebar"},"CUDA101/Organization_of_threads_p2":{"id":"CUDA101/Organization_of_threads_p2","title":"Organization of thread in a CUDA program Part-2","description":"BlockIdx","sidebar":"tutorialSidebar"},"CUDA101/Unique_index_Calculation_p1":{"id":"CUDA101/Unique_index_Calculation_p1","title":"Unique index calculation part-1","description":"- In a #CUDA program it is very common to use #threadIdx, #blockIdx, #blockDim variable value to calculate the array indices. Now it is important to remember why we use #CUDA in the first place, it is because there are no dependencies or very less dependencies in the loop","sidebar":"tutorialSidebar"},"CUDA101/Unique_index_Calculation_p2":{"id":"CUDA101/Unique_index_Calculation_p2","title":"Unique index calculation part-2","description":"Example1: Building up from the previous page assume that there is a grid with 4 blocks 2 in x-dimension and 2 in y-dimension. Each of these blocks have 4 threads in x-dimension only. Write a CUDA program to parse through each element.","sidebar":"tutorialSidebar"}}}')}}]);